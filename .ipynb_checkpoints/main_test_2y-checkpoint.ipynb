{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "14dYVAVpP6Hn",
    "outputId": "c0d4f86a-9957-4af5-8f2a-95db470c6961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Population involed in all traffic accidents:  6772563\n",
      "\n",
      "Total number of all traffic accidents:  2570235\n"
     ]
    }
   ],
   "source": [
    "import local_load_data as ldata\n",
    "import local_param as pm\n",
    "import clean_data as cdata\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_All_years = ldata.start_load(pm.csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYpFR2FIRHWi"
   },
   "outputs": [],
   "source": [
    "#data_years = ldata.get_TrafficData_CSV_year(data_All_years,pm.y_start,pm.y_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9w2_L5UYaoEh"
   },
   "outputs": [],
   "source": [
    "data_cleaned = cdata.data_clean_columns(data_All_years,pm.columns_clean,v_num=pm.v_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGE_ZRpNcrgf"
   },
   "outputs": [],
   "source": [
    "data_cleaned = cdata.modify_data(data_cleaned,pm.columns_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6k6KCxdLlXJl",
    "outputId": "6451b7ec-ab1d-47ac-b147-c5bd54a48344"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1087078,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned['P_ISEV'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "o9skFOf70Z23",
    "outputId": "ecb6d97e-18bd-4e01-e780-d44ebfda8472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_YEAR column data is distributed as below: \n",
      "\n",
      "2015    0.080371\n",
      "2016    0.078234\n",
      "2010    0.068632\n",
      "2011    0.067850\n",
      "2012    0.067016\n",
      "2004    0.064925\n",
      "2017    0.060459\n",
      "2014    0.059459\n",
      "2008    0.057426\n",
      "2013    0.051959\n",
      "2003    0.051213\n",
      "2009    0.049444\n",
      "2007    0.048090\n",
      "2001    0.042086\n",
      "2002    0.040916\n",
      "2006    0.040626\n",
      "2005    0.040182\n",
      "2000    0.015711\n",
      "1999    0.015400\n",
      "Name: C_YEAR, dtype: float64\n",
      "Total size : (1087078,)\n",
      "C_VEHS column data is distributed as below: \n",
      "\n",
      "2    1.0\n",
      "Name: C_VEHS, dtype: float64\n",
      "Total size : (1087078,)\n",
      "C_RSUR column data is distributed as below: \n",
      "\n",
      "1    0.709814\n",
      "2    0.205385\n",
      "3    0.036427\n",
      "5    0.034963\n",
      "4    0.011940\n",
      "6    0.001008\n",
      "7    0.000332\n",
      "8    0.000118\n",
      "9    0.000013\n",
      "Name: C_RSUR, dtype: float64\n",
      "Total size : (1087078,)\n",
      "C_RALN column data is distributed as below: \n",
      "\n",
      "1    0.816733\n",
      "2    0.102767\n",
      "3    0.044640\n",
      "4    0.025428\n",
      "5    0.006392\n",
      "6    0.004039\n",
      "Name: C_RALN, dtype: float64\n",
      "Total size : (1087078,)\n",
      "C_WTHR column data is distributed as below: \n",
      "\n",
      "1    0.733776\n",
      "3    0.114865\n",
      "2    0.085958\n",
      "4    0.049301\n",
      "6    0.010884\n",
      "5    0.003391\n",
      "7    0.001825\n",
      "Name: C_WTHR, dtype: float64\n",
      "Total size : (1087078,)\n",
      "C_CONF column data is distributed as below: \n",
      "\n",
      "21    0.367022\n",
      "35    0.217549\n",
      "36    0.164391\n",
      "33    0.103099\n",
      "22    0.047813\n",
      "31    0.047723\n",
      "23    0.012294\n",
      "06    0.009950\n",
      "24    0.008655\n",
      "32    0.008285\n",
      "34    0.008195\n",
      "03    0.001376\n",
      "04    0.001095\n",
      "25    0.001093\n",
      "41    0.001056\n",
      "02    0.000212\n",
      "01    0.000176\n",
      "05    0.000015\n",
      "Name: C_CONF, dtype: float64\n",
      "Total size : (1087078,)\n",
      "C_RCFG column data is distributed as below: \n",
      "\n",
      "02    0.632439\n",
      "01    0.290277\n",
      "03    0.065874\n",
      "05    0.006114\n",
      "04    0.002147\n",
      "08    0.001932\n",
      "06    0.000665\n",
      "09    0.000495\n",
      "07    0.000031\n",
      "10    0.000026\n",
      "Name: C_RCFG, dtype: float64\n",
      "Total size : (1087078,)\n",
      "V_TYPE column data is distributed as below: \n",
      "\n",
      "01    0.913354\n",
      "06    0.021366\n",
      "05    0.013945\n",
      "14    0.013861\n",
      "07    0.013492\n",
      "08    0.011467\n",
      "11    0.006211\n",
      "09    0.003702\n",
      "17    0.001520\n",
      "18    0.000355\n",
      "23    0.000329\n",
      "10    0.000200\n",
      "21    0.000200\n",
      "Name: V_TYPE, dtype: float64\n",
      "Total size : (1087078,)\n",
      "P_SEX column data is distributed as below: \n",
      "\n",
      "1    0.531543\n",
      "0    0.468457\n",
      "Name: P_SEX, dtype: float64\n",
      "Total size : (1087078,)\n",
      "V_AGE_GRP column data is distributed as below: \n",
      "\n",
      "1     0.339749\n",
      "2     0.326076\n",
      "3     0.236991\n",
      "4     0.075601\n",
      "5     0.015514\n",
      "6     0.003756\n",
      "7     0.001229\n",
      "8     0.000522\n",
      "9     0.000270\n",
      "10    0.000127\n",
      "11    0.000043\n",
      "13    0.000032\n",
      "12    0.000030\n",
      "14    0.000013\n",
      "15    0.000013\n",
      "17    0.000011\n",
      "16    0.000009\n",
      "20    0.000006\n",
      "19    0.000004\n",
      "18    0.000003\n",
      "21    0.000002\n",
      "Name: V_AGE_GRP, dtype: float64\n",
      "Total size : (1087078,)\n",
      "P_AGE_GRP column data is distributed as below: \n",
      "\n",
      "5    0.178872\n",
      "6    0.165903\n",
      "7    0.154847\n",
      "4    0.118750\n",
      "8    0.103502\n",
      "9    0.096825\n",
      "3    0.092176\n",
      "2    0.061926\n",
      "1    0.027199\n",
      "Name: P_AGE_GRP, dtype: float64\n",
      "Total size : (1087078,)\n",
      "P_PSN column data is distributed as below: \n",
      "\n",
      "11    0.689017\n",
      "13    0.176685\n",
      "23    0.055337\n",
      "21    0.043936\n",
      "22    0.015325\n",
      "12    0.010938\n",
      "32    0.004637\n",
      "96    0.003023\n",
      "33    0.000581\n",
      "31    0.000452\n",
      "97    0.000035\n",
      "98    0.000034\n",
      "Name: P_PSN, dtype: float64\n",
      "Total size : (1087078,)\n",
      "P_SAFE column data is distributed as below: \n",
      "\n",
      "02    0.957893\n",
      "01    0.013875\n",
      "09    0.013246\n",
      "13    0.009535\n",
      "12    0.005446\n",
      "10    0.000006\n",
      "Name: P_SAFE, dtype: float64\n",
      "Total size : (1087078,)\n",
      "P_USER column data is distributed as below: \n",
      "\n",
      "1    0.676174\n",
      "2    0.308445\n",
      "5    0.013861\n",
      "4    0.001520\n",
      "Name: P_USER, dtype: float64\n",
      "Total size : (1087078,)\n",
      "P_ISEV column data is distributed as below: \n",
      "\n",
      "2    0.528831\n",
      "1    0.466363\n",
      "3    0.004806\n",
      "Name: P_ISEV, dtype: float64\n",
      "Total size : (1087078,)\n"
     ]
    }
   ],
   "source": [
    "cdata.get_data_stats(data_cleaned,pm.columns_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTMmirJK5IQz"
   },
   "outputs": [],
   "source": [
    "import creat_ML_data as MLdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A863mrYp2dRT"
   },
   "outputs": [],
   "source": [
    "data_selected = MLdata.create_data_for_ML(data_cleaned, pm.traffic_data_headers, pm.dummy_fields, pm.regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oBHwzdK21Fv"
   },
   "outputs": [],
   "source": [
    "test_data, train_x, test_x, train_y, test_y = MLdata.train_test_data(data_selected,pm.time,pm.test_size,pm.year,pm.interval,pm.traffic_data_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULtvC3NN5TlJ"
   },
   "outputs": [],
   "source": [
    "import LR_model_present as LRmp\n",
    "import Tree_model_present as Tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "QrHb8tSP3Od_",
    "outputId": "fc80f755-b3d0-4c6f-da1f-ee5650a3f740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ï¼šNo Injury\n",
      " 2:Injury\n",
      " 3:Fatal\n",
      "\n",
      "p:  l1, C=1.0  \n",
      "Logistic regression parameter {'C': 1.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432357439242418 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594151299373136 \n",
      "\n",
      "p:  l2, C=1.0  \n",
      "Logistic regression parameter {'C': 1.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5433277786154458 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5587304485423894 \n",
      "\n",
      "p:  l1, C=0.0001  \n",
      "Logistic regression parameter {'C': 0.0001, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5522110845015539 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5566003286470695 \n",
      "\n",
      "p:  l2, C=0.0001  \n",
      "Logistic regression parameter {'C': 0.0001, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5452125316002091 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.560464974742864 \n",
      "\n",
      "p:  l1, C=0.00018873918221350977  \n",
      "Logistic regression parameter {'C': 0.00018873918221350977, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5480851888767264 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593238390846571 \n",
      "\n",
      "p:  l2, C=0.00018873918221350977  \n",
      "Logistic regression parameter {'C': 0.00018873918221350977, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5444752749781173 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5601911021848944 \n",
      "\n",
      "p:  l1, C=0.0003562247890262444  \n",
      "Logistic regression parameter {'C': 0.0003562247890262444, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5458420880517431 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593390542267664 \n",
      "\n",
      "p:  l2, C=0.0003562247890262444  \n",
      "Logistic regression parameter {'C': 0.0003562247890262444, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5436587118667964 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.559749863063721 \n",
      "\n",
      "p:  l1, C=0.0006723357536499335  \n",
      "Logistic regression parameter {'C': 0.0006723357536499335, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.544627034309358 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5600998113322379 \n",
      "\n",
      "p:  l2, C=0.0006723357536499335  \n",
      "Logistic regression parameter {'C': 0.0006723357536499335, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5435402416791827 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595977116426267 \n",
      "\n",
      "p:  l1, C=0.0012689610031679222  \n",
      "Logistic regression parameter {'C': 0.0012689610031679222, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5439808332860105 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595672813584079 \n",
      "\n",
      "p:  l2, C=0.0012689610031679222  \n",
      "Logistic regression parameter {'C': 0.0012689610031679222, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5434599560974941 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594759905057514 \n",
      "\n",
      "p:  l1, C=0.002395026619987486  \n",
      "Logistic regression parameter {'C': 0.002395026619987486, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5437478092806216 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594455602215325 \n",
      "\n",
      "p:  l2, C=0.002395026619987486  \n",
      "Logistic regression parameter {'C': 0.002395026619987486, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5434110014745133 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594151299373136 \n",
      "\n",
      "p:  l1, C=0.004520353656360241  \n",
      "Logistic regression parameter {'C': 0.004520353656360241, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5435040152581769 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595064207899701 \n",
      "\n",
      "p:  l2, C=0.004520353656360241  \n",
      "Logistic regression parameter {'C': 0.004520353656360241, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432073502429129 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594607753636419 \n",
      "\n",
      "p:  l1, C=0.008531678524172805  \n",
      "Logistic regression parameter {'C': 0.008531678524172805, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5433992523649979 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5596129267847362 \n",
      "\n",
      "p:  l2, C=0.008531678524172805  \n",
      "Logistic regression parameter {'C': 0.008531678524172805, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432210575373475 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594151299373136 \n",
      "\n",
      "p:  l1, C=0.01610262027560939  \n",
      "Logistic regression parameter {'C': 0.01610262027560939, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5433199458757688 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.559430345079423 \n",
      "\n",
      "p:  l2, C=0.01610262027560939  \n",
      "Logistic regression parameter {'C': 0.01610262027560939, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432416184789994 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593238390846571 \n",
      "\n",
      "p:  l1, C=0.03039195382313198  \n",
      "Logistic regression parameter {'C': 0.03039195382313198, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5433483395570977 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5591869028056722 \n",
      "\n",
      "p:  l2, C=0.03039195382313198  \n",
      "Logistic regression parameter {'C': 0.03039195382313198, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5433121131360918 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594455602215325 \n",
      "\n",
      "p:  l1, C=0.05736152510448681  \n",
      "Logistic regression parameter {'C': 0.05736152510448681, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432778449000053 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595216359320796 \n",
      "\n",
      "p:  l2, C=0.05736152510448681  \n",
      "Logistic regression parameter {'C': 0.05736152510448681, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543150562880255 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.559536851074189 \n",
      "\n",
      "p:  l1, C=0.1082636733874054  \n",
      "Logistic regression parameter {'C': 0.1082636733874054, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432582630508129 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595977116426267 \n",
      "\n",
      "p:  l2, C=0.1082636733874054  \n",
      "Logistic regression parameter {'C': 0.1082636733874054, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432954685642783 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594455602215325 \n",
      "\n",
      "p:  l1, C=0.20433597178569418  \n",
      "Logistic regression parameter {'C': 0.20433597178569418, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432014756881551 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595064207899701 \n",
      "\n",
      "p:  l2, C=0.20433597178569418  \n",
      "Logistic regression parameter {'C': 0.20433597178569418, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431623119897705 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595520662162985 \n",
      "\n",
      "p:  l1, C=0.38566204211634725  \n",
      "Logistic regression parameter {'C': 0.38566204211634725, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432367230167013 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594607753636419 \n",
      "\n",
      "p:  l2, C=0.38566204211634725  \n",
      "Logistic regression parameter {'C': 0.38566204211634725, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432014756881551 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594607753636419 \n",
      "\n",
      "p:  l1, C=0.7278953843983146  \n",
      "Logistic regression parameter {'C': 0.7278953843983146, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432768658075456 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595520662162985 \n",
      "\n",
      "p:  l2, C=0.7278953843983146  \n",
      "Logistic regression parameter {'C': 0.7278953843983146, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543117273736628 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5589434605319213 \n",
      "\n",
      "p:  l1, C=1.3738237958832638  \n",
      "Logistic regression parameter {'C': 1.3738237958832638, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431016082572742 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594151299373136 \n",
      "\n",
      "p:  l2, C=1.3738237958832638  \n",
      "Logistic regression parameter {'C': 1.3738237958832638, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5430497163569145 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594151299373136 \n",
      "\n",
      "p:  l1, C=2.592943797404667  \n",
      "Logistic regression parameter {'C': 2.592943797404667, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431897265786397 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595064207899701 \n",
      "\n",
      "p:  l2, C=2.592943797404667  \n",
      "Logistic regression parameter {'C': 2.592943797404667, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543255325773434 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595064207899701 \n",
      "\n",
      "p:  l1, C=4.893900918477489  \n",
      "Logistic regression parameter {'C': 4.893900918477489, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432024547806148 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593390542267664 \n",
      "\n",
      "p:  l2, C=4.893900918477489  \n",
      "Logistic regression parameter {'C': 4.893900918477489, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431515419727146 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594151299373136 \n",
      "\n",
      "p:  l1, C=9.236708571873866  \n",
      "Logistic regression parameter {'C': 9.236708571873866, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543145667417957 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5590956119530156 \n",
      "\n",
      "p:  l2, C=9.236708571873866  \n",
      "Logistic regression parameter {'C': 9.236708571873866, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432621794206514 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593086239425477 \n",
      "\n",
      "p:  l1, C=17.433288221999874  \n",
      "Logistic regression parameter {'C': 17.433288221999874, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5433816287007247 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594759905057514 \n",
      "\n",
      "p:  l2, C=17.433288221999874  \n",
      "Logistic regression parameter {'C': 17.433288221999874, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543178956561584 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593390542267664 \n",
      "\n",
      "p:  l1, C=32.90344562312671  \n",
      "Logistic regression parameter {'C': 32.90344562312671, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431858102088013 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5585630819791857 \n",
      "\n",
      "p:  l2, C=32.90344562312671  \n",
      "Logistic regression parameter {'C': 32.90344562312671, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431329392159819 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593846996530948 \n",
      "\n",
      "p:  l1, C=62.10169418915616  \n",
      "Logistic regression parameter {'C': 62.10169418915616, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431623119897705 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593542693688759 \n",
      "\n",
      "p:  l2, C=62.10169418915616  \n",
      "Logistic regression parameter {'C': 62.10169418915616, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432866567321418 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594759905057514 \n",
      "\n",
      "p:  l1, C=117.21022975334793  \n",
      "Logistic regression parameter {'C': 117.21022975334793, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431975593183167 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.559430345079423 \n",
      "\n",
      "p:  l2, C=117.21022975334793  \n",
      "Logistic regression parameter {'C': 117.21022975334793, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543171123821907 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595064207899701 \n",
      "\n",
      "p:  l1, C=221.22162910704503  \n",
      "Logistic regression parameter {'C': 221.22162910704503, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543363025943992 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594759905057514 \n",
      "\n",
      "p:  l2, C=221.22162910704503  \n",
      "Logistic regression parameter {'C': 221.22162910704503, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543217141167509 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594759905057514 \n",
      "\n",
      "p:  l1, C=417.53189365604004  \n",
      "Logistic regression parameter {'C': 417.53189365604004, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543158395619932 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.559430345079423 \n",
      "\n",
      "p:  l2, C=417.53189365604004  \n",
      "Logistic regression parameter {'C': 417.53189365604004, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5430937755175972 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593846996530948 \n",
      "\n",
      "p:  l1, C=788.0462815669904  \n",
      "Logistic regression parameter {'C': 788.0462815669904, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5433767332384266 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594759905057514 \n",
      "\n",
      "p:  l2, C=788.0462815669904  \n",
      "Logistic regression parameter {'C': 788.0462815669904, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432239948147264 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5584261457002009 \n",
      "\n",
      "p:  l1, C=1487.3521072935118  \n",
      "Logistic regression parameter {'C': 1487.3521072935118, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5430810473156222 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5593542693688759 \n",
      "\n",
      "p:  l2, C=1487.3521072935118  \n",
      "Logistic regression parameter {'C': 1487.3521072935118, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432318275544032 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.558821739395046 \n",
      "\n",
      "p:  l1, C=2807.2162039411755  \n",
      "Logistic regression parameter {'C': 2807.2162039411755, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431241273838454 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595216359320796 \n",
      "\n",
      "p:  l2, C=2807.2162039411755  \n",
      "Logistic regression parameter {'C': 2807.2162039411755, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543217141167509 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595672813584079 \n",
      "\n",
      "p:  l1, C=5298.316906283702  \n",
      "Logistic regression parameter {'C': 5298.316906283702, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5430967127949761 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595216359320796 \n",
      "\n",
      "p:  l2, C=5298.316906283702  \n",
      "Logistic regression parameter {'C': 5298.316906283702, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.543145667417957 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5594151299373136 \n",
      "\n",
      "p:  l1, C=10000.0  \n",
      "Logistic regression parameter {'C': 10000.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5432024547806148 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5584261457002009 \n",
      "\n",
      "p:  l2, C=10000.0  \n",
      "Logistic regression parameter {'C': 10000.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Logistic regression Train Accuracy :  0.5431486046953358 \n",
      "\n",
      "Logistic regression Test Accuracy :  0.5595672813584079 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "if pm.regression =='lr':\n",
    "  file_name = 't_{}_tst{}_trn{}_Csize_{}_pnt_{}_cw_{}_mltc_{}_svr_{}_cv_{}'.format(pm.time,pm.year,pm.interval,len(pm.C),pm.penalty,pm.classweight,pm.multi_class,pm.solver,pm.cv)\n",
    "  result, all_model = LRmp.build_model_LR(train_x,train_y,test_x,test_y,pm.C,pm.penalty,pm.classweight,pm.multi_class,pm.solver,pm.cv)\n",
    "elif pm.regression =='tree':\n",
    "  file_name = 't_{}_tst{}_trn{}_dep_{}_splt_{}_crt_{}_cw_{}'.format(pm.time,pm.year,pm.interval,pm.max_dep,pm.split_type,pm.crt_type,pm.classweight)\n",
    "  result, all_model = Tmp.build_model_tree(train_x,train_y,test_x,test_y,pm.max_dep,pm.split_type,pm.crt_type,pm.classweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model 0: \n",
      " {'C': 1.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 1: \n",
      " {'C': 1.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 2: \n",
      " {'C': 0.0001, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 3: \n",
      " {'C': 0.0001, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 4: \n",
      " {'C': 0.00018873918221350977, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 5: \n",
      " {'C': 0.00018873918221350977, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 6: \n",
      " {'C': 0.0003562247890262444, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 7: \n",
      " {'C': 0.0003562247890262444, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 8: \n",
      " {'C': 0.0006723357536499335, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 9: \n",
      " {'C': 0.0006723357536499335, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 10: \n",
      " {'C': 0.0012689610031679222, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 11: \n",
      " {'C': 0.0012689610031679222, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 12: \n",
      " {'C': 0.002395026619987486, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 13: \n",
      " {'C': 0.002395026619987486, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 14: \n",
      " {'C': 0.004520353656360241, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 15: \n",
      " {'C': 0.004520353656360241, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 16: \n",
      " {'C': 0.008531678524172805, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 17: \n",
      " {'C': 0.008531678524172805, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 18: \n",
      " {'C': 0.01610262027560939, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 19: \n",
      " {'C': 0.01610262027560939, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 20: \n",
      " {'C': 0.03039195382313198, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 21: \n",
      " {'C': 0.03039195382313198, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 22: \n",
      " {'C': 0.05736152510448681, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 23: \n",
      " {'C': 0.05736152510448681, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 24: \n",
      " {'C': 0.1082636733874054, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 25: \n",
      " {'C': 0.1082636733874054, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 26: \n",
      " {'C': 0.20433597178569418, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 27: \n",
      " {'C': 0.20433597178569418, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 28: \n",
      " {'C': 0.38566204211634725, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 29: \n",
      " {'C': 0.38566204211634725, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 30: \n",
      " {'C': 0.7278953843983146, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 31: \n",
      " {'C': 0.7278953843983146, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 32: \n",
      " {'C': 1.3738237958832638, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 33: \n",
      " {'C': 1.3738237958832638, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 34: \n",
      " {'C': 2.592943797404667, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 35: \n",
      " {'C': 2.592943797404667, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 36: \n",
      " {'C': 4.893900918477489, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 37: \n",
      " {'C': 4.893900918477489, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 38: \n",
      " {'C': 9.236708571873866, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 39: \n",
      " {'C': 9.236708571873866, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 40: \n",
      " {'C': 17.433288221999874, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 41: \n",
      " {'C': 17.433288221999874, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 42: \n",
      " {'C': 32.90344562312671, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 43: \n",
      " {'C': 32.90344562312671, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 44: \n",
      " {'C': 62.10169418915616, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 45: \n",
      " {'C': 62.10169418915616, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 46: \n",
      " {'C': 117.21022975334793, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 47: \n",
      " {'C': 117.21022975334793, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 48: \n",
      " {'C': 221.22162910704503, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 49: \n",
      " {'C': 221.22162910704503, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 50: \n",
      " {'C': 417.53189365604004, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 51: \n",
      " {'C': 417.53189365604004, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 52: \n",
      " {'C': 788.0462815669904, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 53: \n",
      " {'C': 788.0462815669904, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 54: \n",
      " {'C': 1487.3521072935118, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 55: \n",
      " {'C': 1487.3521072935118, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 56: \n",
      " {'C': 2807.2162039411755, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 57: \n",
      " {'C': 2807.2162039411755, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 58: \n",
      " {'C': 5298.316906283702, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 59: \n",
      " {'C': 5298.316906283702, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 60: \n",
      " {'C': 10000.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "model 61: \n",
      " {'C': 10000.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "orders = ['Accuracy']  + [col for col in result if col != 'Accuracy']\n",
    "result = result[orders]\n",
    "file_name = 't_{}_tst{}_trn{}_Csize_{}_pnt_{}_cw_{}_mltc_{}_svr_{}_cv_{}'.format(pm.time,pm.year,pm.interval,len(pm.C),pm.penalty,pm.classweight,pm.multi_class,pm.solver,pm.cv)\n",
    "result.to_csv(pm.regression+'_accuracy_result'+file_name+'.csv') \n",
    "import local_Result_Analysis as RA\n",
    "allmodel_Acc_error_mean_sqrt,allmodel_victim_error_mean_sqrt,allmodel_Acc_error_mean,allmodel_victim_error_mean = RA.compare_model(test_data, test_x, all_model,pm.money_path)\n",
    "allmodel_Acc_error_mean_sqrt.to_csv(file_name+'allmodel_Acc_error_mean_sqrt.csv')\n",
    "allmodel_victim_error_mean_sqrt.to_csv(file_name+'allmodel_victim_error_mean_sqrt.csv')\n",
    "allmodel_Acc_error_mean.to_csv(file_name+'allmodel_Acc_error_mean.csv')\n",
    "allmodel_victim_error_mean.to_csv(file_name+'allmodel_victim_error_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
